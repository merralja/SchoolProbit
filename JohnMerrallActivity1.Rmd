---
title: "School Probit"
author: "John Merrall"
date: "04/10/2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(dplyr)
```


# A school probit

I want to do a probit on whether or not DAs that saw an increase or decrease in income or youth population, between 2006 and 2016, were more or less likely to lose their local public primary school to amalgamation.

# 1. Data preprocessing

Let's start by loading 2006 and 2016 census data, as downloaded from CHASS. Then we will cut out all DAs that were NA for data in 2006.

```{r load-census, echo = FALSE, message = FALSE, warning=FALSE}
CENSUS2006DATA <- read.csv(file="CENSUS2006DATA.csv", header=TRUE, sep=",")
CENSUS2016DATA <- read.csv(file="CENSUS2016DATA.csv", header=TRUE, sep=",")
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(AVGAFTERTAXINC))
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(PERCLOWINC0TO5))
#
# for some weird reason, there's also areas with 0 reported average after tax income.
# I guess I can't use those in my work either, if I want to calculate delta incomes!
# So they have to go as well.
#
CENSUS2006DATA <- subset(CENSUS2006DATA, AVGAFTERTAXINC>0)
```


Next, we need to trim out some excess columns in the 2006 file, and rename some columns to make keeping track of variables easier:

```{r trim-columns, echo = FALSE, message = FALSE, warning=FALSE}
head((CENSUS2006DATA <- CENSUS2006DATA %>%
select(DAUID, POP2006, POP0TO14ADD, PERCLOWINC0TO5, AVGAFTERTAXINC)))
# note I had already calculated pop0to14 outside of R in libreoffice before I started this work
```
```{r rename, echo = FALSE, message = FALSE, warning=FALSE}
CE06 <- CENSUS2006DATA %>% 
  rename(
    POP0TO142006 = POP0TO14ADD,
    PERCLOWINC0TO52006 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2006 = AVGAFTERTAXINC
    )
CE16 <- CENSUS2016DATA %>%
  rename(
    POP0TO142016 = POP0TO14,
    PERCLOWINC0TO52016 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2016 = AVGAFTERTAXINCOME
  )
```

##Dealing with split DAs

We next need to check which 2006 DAs disappeared by 2016, according to our two census files. These split DAs need to be rebuilt using 2016 data so that we can calculate deltas for them.

```{r find-split-das, echo = FALSE, message = FALSE, warning=FALSE}
(in2006not2016 <- anti_join(CE06,CE16))
```

Thankfully, this calculation yields only 23 DAs of 2006 that were split into smaller DAs in 2011 and 2016. I have manually generated a list of split DAs, confirmed by inspection in ArcGIS, and it agrees with the above generated list.

So let's fake the 2016 pop etc. data for those 23 split 2006 DAs by hand. 

I could just have easily done the math in excel before loading the files in R, but at least you get to track all my math here.

```{r combine-das, echo = FALSE, message = FALSE, warning=FALSE}
# the default for "merge" will do a join while dropping 2006 DAs found in in2006not2016
# so we have to keep those by saying all.x = "TRUE"
# it also has no problem bringing "NA" data from 2016
# so we will have to drop those later on
#
finaldf <- merge(CE06, CE16, by = "DAUID", all.x = "TRUE")
# now we add in all the split-DA data by hand
# ONE AT A TIME
#
# DAUID==35250063
#
finaldf$POP2016[finaldf$DAUID==35250063] <- (CE16$POP2016[CE16$DAUID==35250999] + CE16$POP2016[CE16$DAUID==35250998])
#
finaldf$POP0TO142016[finaldf$DAUID==35250063] <- (CE16$POP0TO142016[CE16$DAUID==35250999] + CE16$POP0TO142016[CE16$DAUID==35250998])
#
# this is a bit kludged, I should have downloaded number of households to average this 
# by household instead of by population.
# could fix it later
# (though these are all new neighbourhoods, so we can assume in approximation that all the
# households are homogeneous in size)
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250063] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
#
# and for perclowinc0to5, this really does just take population proportions to solve
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250063] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
# 
# now we just have to do this for the other 22 split DAs
#
# then we delete all the data that is NA for 2016
#
# so let's do all the rest here.
#
# DA = 35250132
#
finaldf$POP2016[finaldf$DAUID==35250132] <- (CE16$POP2016[CE16$DAUID==35250981] + CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250132] <- (CE16$POP0TO142016[CE16$DAUID==35250981] + CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250132] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250132] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
# DA = 35250154
#
finaldf$POP2016[finaldf$DAUID==35250154] <- (CE16$POP2016[CE16$DAUID==35251003] + CE16$POP2016[CE16$DAUID==35251004] + CE16$POP2016[CE16$DAUID==35251005] + CE16$POP2016[CE16$DAUID==35251006])
#
finaldf$POP0TO142016[finaldf$DAUID==35250154] <- (CE16$POP0TO142016[CE16$DAUID==35251003] + CE16$POP0TO142016[CE16$DAUID==35251004] + CE16$POP0TO142016[CE16$DAUID==35251005] + CE16$POP0TO142016[CE16$DAUID==35251006])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250154] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250154] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
# DA = 35250155
#
finaldf$POP2016[finaldf$DAUID==35250155] <- (CE16$POP2016[CE16$DAUID==35251007] + CE16$POP2016[CE16$DAUID==35251008] + CE16$POP2016[CE16$DAUID==35251009] + CE16$POP2016[CE16$DAUID==35251010])
#
finaldf$POP0TO142016[finaldf$DAUID==35250155] <- (CE16$POP0TO142016[CE16$DAUID==35251007] + CE16$POP0TO142016[CE16$DAUID==35251008] + CE16$POP0TO142016[CE16$DAUID==35251009] + CE16$POP0TO142016[CE16$DAUID==35251010])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250155] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250155] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
# DA = 35250171
#
finaldf$POP2016[finaldf$DAUID==35250171] <- (CE16$POP2016[CE16$DAUID==35251027] + CE16$POP2016[CE16$DAUID==35251028])
#
finaldf$POP0TO142016[finaldf$DAUID==35250171] <- (CE16$POP0TO142016[CE16$DAUID==35251027] + CE16$POP0TO142016[CE16$DAUID==35251028])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250171] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250171] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
# DA = 35250174
#
finaldf$POP2016[finaldf$DAUID==35250174] <- (CE16$POP2016[CE16$DAUID==35251029] + CE16$POP2016[CE16$DAUID==35251030])
#
finaldf$POP0TO142016[finaldf$DAUID==35250174] <- (CE16$POP0TO142016[CE16$DAUID==35251029] + CE16$POP0TO142016[CE16$DAUID==35251030])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250174] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250174] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
# DA = 35250182
# This was a simple rename to 25350982, except probably the edges changed.
# I'm ingoring minor changes to DA boundaries, because that won't hurt me any more than
# ignoring the ecological fallacy.
#
finaldf$POP2016[finaldf$DAUID==35250182] <- (CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250182] <- (CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250182] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250182] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250982])
#
# DA = 35250187
#
finaldf$POP2016[finaldf$DAUID==35250187] <- (CE16$POP2016[CE16$DAUID==35250985])
#
finaldf$POP0TO142016[finaldf$DAUID==35250187] <- (CE16$POP0TO142016[CE16$DAUID==35250985])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250187] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250985])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250187] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250985])
#
# DA = 35250577
#
finaldf$POP2016[finaldf$DAUID==35250577] <- (CE16$POP2016[CE16$DAUID==35251011] + CE16$POP2016[CE16$DAUID==35251012] + CE16$POP2016[CE16$DAUID==35251013] + CE16$POP2016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$POP0TO142016[finaldf$DAUID==35250577] <- (CE16$POP0TO142016[CE16$DAUID==35251011] + CE16$POP0TO142016[CE16$DAUID==35251012] + CE16$POP0TO142016[CE16$DAUID==35251013] + CE16$POP0TO142016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250577] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250577] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
# DA = 35250584
#
finaldf$POP2016[finaldf$DAUID==35250584] <- (CE16$POP2016[CE16$DAUID==35250998] + CE16$POP2016[CE16$DAUID==35250999])
#
finaldf$POP0TO142016[finaldf$DAUID==35250584] <- (CE16$POP0TO142016[CE16$DAUID==35250998] + CE16$POP0TO142016[CE16$DAUID==35250999])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250584] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250584] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
# DA = 35250653
#
finaldf$POP2016[finaldf$DAUID==35250653] <- (CE16$POP2016[CE16$DAUID==35251016] + CE16$POP2016[CE16$DAUID==35251017] + CE16$POP2016[CE16$DAUID==35251018])
#
finaldf$POP0TO142016[finaldf$DAUID==35250653] <- (CE16$POP0TO142016[CE16$DAUID==35251016] + CE16$POP0TO142016[CE16$DAUID==35251017] + CE16$POP0TO142016[CE16$DAUID==35251018])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250653] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250653] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
# DA = 35250808
#
finaldf$POP2016[finaldf$DAUID==35250808] <- (CE16$POP2016[CE16$DAUID==35251019] + CE16$POP2016[CE16$DAUID==35251020] + CE16$POP2016[CE16$DAUID==35251021])
#
finaldf$POP0TO142016[finaldf$DAUID==35250808] <- (CE16$POP0TO142016[CE16$DAUID==35251019] + CE16$POP0TO142016[CE16$DAUID==35251020] + CE16$POP0TO142016[CE16$DAUID==35251021])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250808] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250808] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
# DA = 35250809
#
finaldf$POP2016[finaldf$DAUID==35250809] <- (CE16$POP2016[CE16$DAUID==35251022] + CE16$POP2016[CE16$DAUID==35251023] + CE16$POP2016[CE16$DAUID==35251024])
#
finaldf$POP0TO142016[finaldf$DAUID==35250809] <- (CE16$POP0TO142016[CE16$DAUID==35251022] + CE16$POP0TO142016[CE16$DAUID==35251023] + CE16$POP0TO142016[CE16$DAUID==35251024])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250809] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250809] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
# DA = 35250840
#
finaldf$POP2016[finaldf$DAUID==35250840] <- (CE16$POP2016[CE16$DAUID==35251025] + CE16$POP2016[CE16$DAUID==35251026])
#
finaldf$POP0TO142016[finaldf$DAUID==35250840] <- (CE16$POP0TO142016[CE16$DAUID==35251025] + CE16$POP0TO142016[CE16$DAUID==35251026])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250840] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250840] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
# DA = 35850841
#
finaldf$POP2016[finaldf$DAUID==35250841] <- (CE16$POP2016[CE16$DAUID==35250990] + CE16$POP2016[CE16$DAUID==35250991] + CE16$POP2016[CE16$DAUID==35250992])
#
finaldf$POP0TO142016[finaldf$DAUID==35250841] <- (CE16$POP0TO142016[CE16$DAUID==35250990] + CE16$POP0TO142016[CE16$DAUID==35250991] + CE16$POP0TO142016[CE16$DAUID==35250992])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250841] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250841] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
# DA = 35250842
#
finaldf$POP2016[finaldf$DAUID==35250842] <- (CE16$POP2016[CE16$DAUID==35250986] + CE16$POP2016[CE16$DAUID==35250987])
#
finaldf$POP0TO142016[finaldf$DAUID==35250842] <- (CE16$POP0TO142016[CE16$DAUID==35250986] + CE16$POP0TO142016[CE16$DAUID==35250987])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250842] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250842] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
# DA = 35250844
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250858
# 
finaldf$POP2016[finaldf$DAUID==35250858] <- (CE16$POP2016[CE16$DAUID==35251000] + CE16$POP2016[CE16$DAUID==35251001] + CE16$POP2016[CE16$DAUID==35251002])
#
finaldf$POP0TO142016[finaldf$DAUID==35250858] <- (CE16$POP0TO142016[CE16$DAUID==35251000] + CE16$POP0TO142016[CE16$DAUID==35251001] + CE16$POP0TO142016[CE16$DAUID==35251002])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250858] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250858] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
# DA = 35250915
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income too, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250916
# this next one's a monster, it got split into 6 DAs by 2016!
#
finaldf$POP2016[finaldf$DAUID==35250916] <- (CE16$POP2016[CE16$DAUID==35251033] + CE16$POP2016[CE16$DAUID==35251035] + CE16$POP2016[CE16$DAUID==35251036] + CE16$POP2016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$POP0TO142016[finaldf$DAUID==35250916] <- (CE16$POP0TO142016[CE16$DAUID==35251033] + CE16$POP0TO142016[CE16$DAUID==35251035] + CE16$POP0TO142016[CE16$DAUID==35251036] + CE16$POP0TO142016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250916] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250916] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
# DA = 35250917
#
finaldf$POP2016[finaldf$DAUID==35250917] <- (CE16$POP2016[CE16$DAUID==35250996] + CE16$POP2016[CE16$DAUID==35250997])
#
finaldf$POP0TO142016[finaldf$DAUID==35250917] <- (CE16$POP0TO142016[CE16$DAUID==35250996] + CE16$POP0TO142016[CE16$DAUID==35250997])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250917] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250917] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
# DA = 35250926
#
finaldf$POP2016[finaldf$DAUID==35250926] <- (CE16$POP2016[CE16$DAUID==35250976] + CE16$POP2016[CE16$DAUID==35250980])
#
finaldf$POP0TO142016[finaldf$DAUID==35250926] <- (CE16$POP0TO142016[CE16$DAUID==35250976] + CE16$POP0TO142016[CE16$DAUID==35250980])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250926] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250926] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
# DA = 35250927
#
finaldf$POP2016[finaldf$DAUID==35250927] <- (CE16$POP2016[CE16$DAUID==35250978])
#
finaldf$POP0TO142016[finaldf$DAUID==35250927] <- (CE16$POP0TO142016[CE16$DAUID==35250978])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250927] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250978])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250927] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250978])
```

Next we need to strip out all the other DAs that have an NA for 2016 data:

```{r strip-2016-nas, echo = FALSE, message = FALSE, warning=FALSE}
# now we strip out all 2016 NAs
#
finaldf <- subset(finaldf, !is.na(AVGAFTERTAXINCHH2016))
finaldf <- subset(finaldf, !is.na(PERCLOWINC0TO52016))
finaldf <- subset(finaldf, AVGAFTERTAXINCHH2016>0)
```

So now we can calculate delta household after-tax income for each DA, and delta pop 0-14 for each DA.

I think right now that I want absolute delta pop 0 to 14 and not a proportion, because school enrolment is dependent on absolute numbers, not proportions. If not, I'll come back and change this code later.

I also might want to split delta income categories into quintiles instead of simple above-below - or maybe even change my delta income from simple above-below to some other cutoff. We'll see.

```{r calc-deltas, echo = FALSE, message = FALSE, warning=FALSE}
# calculated delta income, and the flag
finaldf$deltaincome <- finaldf$AVGAFTERTAXINCHH2016/finaldf$AVGAFTERTAXINCHH2006
finaldf$deltaincoveravg <- as.integer(finaldf$deltaincome > finaldf$deltaincome[finaldf$DAUID==3525])
# calculate delta pop 0 to 14
finaldf$deltapop0to14 <- finaldf$POP0TO142016 - finaldf$POP0TO142006
```

What's the final look like now?

```{r}
head(finaldf)
```

## Flagging DAs for school closure

In ArcGIS, I did a spatial join between HWDSB elementary school catchments and DAs. The file created is called Join_Output (included in the ArcGIS subdirectory). Afterwards, I went through and manually verified the condition of each DA, changing the MAX-CLOSED column values to suit the following rubric:

0 - DA is completely outside closed catchment
1 - DA is completely inside closed catchment
2 - DA is about 70-90% inside closed catchment
3 - DA is about 30-70% inside closed catchment
4 - DA is maybe only 10-30% inside closed catchment
9 - DA is outside closed catchment, but was labelled as inside because its border is sort of coincident with the closed catchment border and these 2 layers don't exactly tesselate.

So now, we have a set of 2006 Dissemination Area polygons for Hamilton, and we can start looking at the data.

# 2. Data exploration

So let's start by loading Join_Output, the ArcGIS DA geometry file that includes flags for school closure. Then we coerce DAgeometry DAUID into integer, which apparently has to be done the long way round cos it's a factor; then we delete extraneous columns; then we join into the 2006 census file.

```{Delete extraneous columns:}
library(sf)
```


```{r join-public-sf, echo = FALSE, message = FALSE, warning=FALSE}
DAgeometry <- st_read("./ArcGIS", layer = "Join_Output")
DAgeometry <- mutate(DAgeometry, DAUID = as.integer(as.character(DAUID)))
DAs <- DAgeometry %>%
select(DAUID, Max_CLOSED, geometry)
DAsj <- inner_join(DAs, finaldf)
```

Note that DAsj has one less row than finaldf, because finaldf contains the summary row for 3525, i.e. the data sum for all Hamilton.

```{r}
library(ggplot2)
```

##First probit

Now, I guess, we can probit:

pr(Isschoolclosed) ~ deltaincoveravg + deltapop0to14 + PERCLOWINC0TO52006

So let's generate the dependent variable, first by taking any DA with Max_CLOSED = 1 or 2. This gives a 1 value to any DA whose boundary is 70% or more inside the 2006 catchment of a school that later closed.

```{r gen-isclosed, echo = FALSE, message = FALSE, warning=FALSE}
DAsj$Isschoolclosed <- as.numeric(DAsj$Max_CLOSED==1 | DAsj$Max_CLOSED==2)
```

So here is a zoomable map of the areas where schools have closed.

```{r load-tmap, echo = FALSE, message = FALSE, warning=FALSE}
library(tmap)
```



```{r zoomable-map, echo = FALSE, message = FALSE, warning=FALSE}
tmap_mode("view")
pal1 <- c("green", "red")
tm_shape(DAsj) + tm_polygons("Isschoolclosed", palette = pal1)
```


And so you can pretty much see the schools that were closed: Central Park in Dundas, Prince Philip in West Hamilton, Woodward and Roxborough Park in the east city; Linden Park and Eastmount Park on the Mountain; and Gibson, King George and Stinson downtown.

Before we do the probit, I'd like to look at some variables:



```{r zoomable-maps, echo = FALSE, message = FALSE, warning=FALSE}
tmap_mode("view")
tm_shape(DAsj) +
tm_fill(c("deltapop0to14", "deltaincome"),title=c("Delta 0 to 14 pop", "delta income"), n=c(6,10), style=c("quantile", "jenks"), palette="YlOrBr") +  
  tm_facets(sync = TRUE, ncol = 2)
```

```{r zoomable-income, echo = FALSE, message = FALSE, warning=FALSE}
tmap_mode("view")
tm_shape(DAsj) + tm_polygons(c("AVGAFTERTAXINCHH2006", "PERCLOWINC0TO52006"),n=c(6,6)) +
  tm_facets(sync = TRUE, ncol = 2)
```


Later I want to do some area analysis on this. The maps are a bit uninformative: deltapop0to14 is skewed by a couple areas of higher settlement, and deltaincome is skewed by the DA around the airport (which has seen a couple large mansions get built in the past 10-15 years, though I don't think 2 high income earners can skew a DA income by that much.)

Anyway, let's probit:

```{r}
myprobit <- glm(Isschoolclosed ~ deltaincome + deltapop0to14 + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj)

## model summary
summary(myprobit)

```

So basically, right now it looks like the only significant variable is whether income grew faster than average: Areas that saw less income growth were ones where the primary school closed.

Since we don't have causality in this, only correlation, I guess we can't right now infer much... can we say that the downtown areas that saw school closures were less likely to see gentrification influx?

Discussion with AP on 7 Oct 2019 yielded that I should include POP0TO142006 and AVGAFTERTAXINCHH2006. Let's do that now:

```{r}
myprobit <- glm(Isschoolclosed ~ deltaincome + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj)
summary(myprobit)
```

AP will like this! deltaincome is still a significant negative predictor of school closure, and average after-tax household income in 2006 is also a very significant negative predictor.

So we can conclude from AVGAFTERTAXINCHH2006 that DAs with lower income in 2006 were much more likely to see their school close; however, areas that saw high positive income gains were also much less likely to see their school close.

What about age 0 to 14 proportion of population change, instead?

```{r}
#poop, I forgot to subset out POP2006 NAs!
DAsj <- subset(DAsj, !is.na(POP2006))
```


```{r}
DAsj$deltaperckids <- DAsj$deltapop0to14 / DAsj$POP2006
myprobit <- glm(Isschoolclosed ~ deltaincome + deltaperckids + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj)
summary(myprobit)
```

In case we think that higher income DAs see higher delta income from 2006 to 2016:

```{r}
a <- lm(deltaincome ~ log(AVGAFTERTAXINCHH2006), data=DAsj)
summary(a)
```

No, it's not true at all. Slight negative coefficient with a good p-value, but actually nearly 0 R-squared, so pretty much no explanatory value.

##Gentrification?

Can we look specifically at "gentrification"? If a gentrifying neighbourhood is defined as one where average HH income grew faster than average AND kids decreased, then:

```{r}
DAsj$gent <- as.numeric(DAsj$deltaincoveravg==1) * as.numeric(DAsj$deltapop0to14<=0)
```

Let's add that to our full probit:

```{r}
myprobit <- glm(Isschoolclosed ~ deltaincome + deltaperckids + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006 + gent, family = binomial(link = "probit"), data = DAsj)

## model summary
summary(myprobit)
```

Hm.

This looks to me like neighbourhoods that saw their old school close from 2006 to 2016 gentrified _more_ (p=0.17, I know that's not great but it is the vaguest of proof). 

---

# Catholic school closures

The same analysis can be done for Catholic school closures, with one caveat: Catholic grade school closures from 2006-2010 are known, but boundaries for 2006-2010 were not available. 

The following assumptions had to be made for Catholic schools:

1. St. Christopher (closed in June 2008) is known from news reports to have had a boundary with St. John the Baptist along the railway line by Larence Road;
2. St. Helen's (closed June 2009) east boundary was assumed to be the Red Hill Expressway;
3. St. Mary Elementary (closed June 2009) was assumed to share a boundary with St. Lawrence along the north end railway;
4. Holy Family (closed 2009) was assumed to have a boundary along Ottawa Street. This is the most questionable assumption, since it means Holy Name of Jesus had a catchment twice the size, although its enrolment numbers were roughly equal.
5. St. Jerome and Catherine of Siena are known to have had a boundary along the Linc.

With that caveat in mind,

We can first load the Catholic DA shapefile data, strip geometry (since all we want is the closure flag), then join it, then generate an isschoolclosed2 variable:

```{r join-Cath-sf, echo = FALSE, message = FALSE, warning=FALSE}
DAcath <- st_read("./ArcGIS/CATHOLIC", layer = "Join_Cath")
DAcath <- mutate(DAcath, DAUID = as.integer(as.character(DAUID)))
DAcath <- DAcath %>% 
  rename(
    Cath_CLOSED = Max_CLOSED
    )
st_geometry(DAcath) <- NULL
DAcath <- DAcath %>% select(DAUID, Cath_CLOSED)
DAsj2 <- inner_join(DAsj, DAcath)
DAsj2$Isschoolclosed2 <- as.numeric(DAsj2$Cath_CLOSED==1 | DAsj2$Cath_CLOSED==2)
```

Let's look at a map of the Catholic school closures:


```{r zoomable-mapC, echo = FALSE, message = FALSE, warning=FALSE}
tmap_mode("view")
#qtm(ridings, fill = "Isschoolclosed")
pal1 <- c("green", "red")
tm_shape(DAsj2) + tm_polygons("Isschoolclosed2", palette = pal1)
```

And nopw we can do another probit, this time for Catholic school closures, on the variables suggested by AP:

```{r}
myprobit2 <- glm(Isschoolclosed2 ~ deltaincome + deltapop0to14 + deltaperckids + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006 + gent, family = binomial(link = "probit"), data = DAsj2)

## model summary
summary(myprobit2)
```

Compare the Catholic result to the public board result. In the Catholic case, the p value for deltaincome is not significant, but after tax household income 2006 is still a negative predictor of school closure. Also, areas with a decrease in children as percent of population saw schools more likely to close.

## EXTRA: density plots?

Let's see if I can do some density plots to show differences:

```{r}
# Change line color by sex
a <- ggplot(DAsj, aes(x = AVGAFTERTAXINCHH2006))
a + geom_density(aes(color = as.factor(Isschoolclosed))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6)
```


```{r}
a <- ggplot(DAsj2, aes(x = AVGAFTERTAXINCHH2006))
a + geom_density(aes(color = as.factor(Isschoolclosed2))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6)
```






# Next to do

1. As an aside, I want to do some area analysis of the census variables, because that checkerboard pattern for deltaincome concerns me.

2. Also want to do some dot plots. Go to AP's R code for real estate and look at what he does there.

