---
title: Probit Analysis of School Closures in Hamilton Ontario
author:
  - name: John Merrall
    email: merralja@mcmaster.ca
    affiliation: School of Geography and Earth Sciences, McMaster University
    footnote: Corresponding Author
address:
  - code: School of Geography and Earth Sciences, McMaster University
    address: General Sciences Rm. 206, McMaster University, 1280 Main Street West, Hamilton, Ontario L8S 4K1
abstract: |
  Does the process of school closures and amalgamation negatively affect students from poorer socioecoomic backgrounds?
  This study uses census data and historical school catchment maps to study the distributional effects of school closures in Hamilton, Ontario from 2006 to 2016.

journal: "Journal for Doing Spatial Stuff"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
#linenumbers: true
#numbersections: true
csl: elsevier-harvard.csl
output: rticles::elsevier_article
---



```{r load-packages, include = FALSE}
library(dplyr)
library(ggplot2)
library(kableExtra)
library(rticles)
library(sf)
library(gridExtra)
library(tidyverse)
library(tmap)
```


Introduction
============

School closures in the city of Hamilton became a contentious issue in 2002, when the Harris government appointed Jim Murray as special supervisor to oversee a rationalization of the Hamilton-Wentworth District School Board (HWDSB) in the face of trustee opposition to closure of under-utilized schools (@Honey; @Prokaska). The following years saw a wave of public board school closures and replacements in Hamilton, aiming to reduce per-pupil education costs in the face of urban demographic change, and to access new provincial construction funding. Resistance to the consolidation process eventually relented, and this accommodation review system has since become institutionalized at the HWDSB; the Hamilton Catholic board (HWCDSB), facing similar overcapacity issues, has followed suit.

Given the wave of school reorganizations that occurred over the past twenty years, it makes sense to look at whether these closures had a social equity effect: neighbourhoods certainly didn't suddenly find themselves without any school at all, but distance to schools would have increased in areas where school closures occurred. Did this increase in walking distance disproportionately affect the poor?

This paper will examine the likelihood of a HWDSB or HWCDSB school being closed between the years of 2006 and 2016, dependent on the income and deprivation characteristics and trends of each census dissemination area over that same period of time. 


Data
====

## Census Data

```{r load-census, include = FALSE}
#
# here we are loading 2006 and 2016 DA-level census data which has been downloaded from CHASS.
#
CENSUS2006DATA <- read.csv(file="CENSUS2006DATA.csv", header=TRUE, sep=",")
CENSUS2016DATA <- read.csv(file="CENSUS2016DATA.csv", header=TRUE, sep=",")
#
# the problem with using this data is that we will have a fair number of NAs.
# we subset out the NA data here:
#
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(AVGAFTERTAXINC))
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(PERCLOWINC0TO5))
#
# for some weird reason, there's also areas with 0 reported average after tax income.
# I guess I can't use those in my work either, if I want to calculate delta incomes!
# So they have to go as well.
#
CENSUS2006DATA <- subset(CENSUS2006DATA, AVGAFTERTAXINC>0)
#
# and trim excess columns
#
CENSUS2006DATA <- CENSUS2006DATA %>% select(DAUID, POP2006, POP0TO14ADD, PERCLOWINC0TO5, AVGAFTERTAXINC)
```

First, a compact set of Hamilton dissemination area level census data and GIS dissemination area shapefiles for census years 2006 and 2016 were downloaded from CHASS; areas with NA or zero values for Average After-Tax Income, and NA values for Percent Children 0-5 Low Income, were dropped from the dataset. Since this paper's analysis is performed at the 2006 dissemination area level of support, 2016 data was appended to the 2006 data frame; the 23 dissemination areas of 2006 which were split by the time of the 2016 census were identified in R, verified manually in ArcGIS, and 2016 data was then manipulated to append to the data frames for those subsequently-split 2006 DAs. Then, the 2006 and 2016 data was used to calculate each DA's percent change in average household after-tax income, and absolute change in population ages 0 to 14. 

```{r data-preparation, include=FALSE}
#
# renaming files and columns to make following the code easier:
#
CE06 <- CENSUS2006DATA %>% 
  rename(
    POP0TO142006 = POP0TO14ADD,
    PERCLOWINC0TO52006 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2006 = AVGAFTERTAXINC
    )
CE16 <- CENSUS2016DATA %>%
  rename(
    POP0TO142016 = POP0TO14,
    PERCLOWINC0TO52016 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2016 = AVGAFTERTAXINCOME
  )
#
# find split DAs - this code can be run and the data frame inspected if you wish
#
in2006not2016 <- anti_join(CE06,CE16)
#
# this next bit of code is a doozy
#
# the default for "merge" will do a join while dropping 2006 DAs found in in2006not2016
# so we have to keep those by saying all.x = "TRUE"
# it also has no problem bringing "NA" data from 2016
# so we will have to drop those later on
#
finaldf <- merge(CE06, CE16, by = "DAUID", all.x = "TRUE")
# now we add in all the split-DA data by hand
# ONE AT A TIME
#
# DAUID==35250063
#
finaldf$POP2016[finaldf$DAUID==35250063] <- (CE16$POP2016[CE16$DAUID==35250999] + CE16$POP2016[CE16$DAUID==35250998])
#
finaldf$POP0TO142016[finaldf$DAUID==35250063] <- (CE16$POP0TO142016[CE16$DAUID==35250999] + CE16$POP0TO142016[CE16$DAUID==35250998])
#
# this is a bit kludged, I should have downloaded number of households to average this 
# by household instead of by population.
# could fix it later
# (though these are all new neighbourhoods, so we can assume in approximation that all the
# households are homogeneous in size)
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250063] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
#
# and for perclowinc0to5, this really does just take population proportions to solve
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250063] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
# 
# now we just have to do this for the other 22 split DAs
#
# then we delete all the data that is NA for 2016
#
# so let's do all the rest here.
#
# DA = 35250132
#
finaldf$POP2016[finaldf$DAUID==35250132] <- (CE16$POP2016[CE16$DAUID==35250981] + CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250132] <- (CE16$POP0TO142016[CE16$DAUID==35250981] + CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250132] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250132] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
# DA = 35250154
#
finaldf$POP2016[finaldf$DAUID==35250154] <- (CE16$POP2016[CE16$DAUID==35251003] + CE16$POP2016[CE16$DAUID==35251004] + CE16$POP2016[CE16$DAUID==35251005] + CE16$POP2016[CE16$DAUID==35251006])
#
finaldf$POP0TO142016[finaldf$DAUID==35250154] <- (CE16$POP0TO142016[CE16$DAUID==35251003] + CE16$POP0TO142016[CE16$DAUID==35251004] + CE16$POP0TO142016[CE16$DAUID==35251005] + CE16$POP0TO142016[CE16$DAUID==35251006])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250154] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250154] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
# DA = 35250155
#
finaldf$POP2016[finaldf$DAUID==35250155] <- (CE16$POP2016[CE16$DAUID==35251007] + CE16$POP2016[CE16$DAUID==35251008] + CE16$POP2016[CE16$DAUID==35251009] + CE16$POP2016[CE16$DAUID==35251010])
#
finaldf$POP0TO142016[finaldf$DAUID==35250155] <- (CE16$POP0TO142016[CE16$DAUID==35251007] + CE16$POP0TO142016[CE16$DAUID==35251008] + CE16$POP0TO142016[CE16$DAUID==35251009] + CE16$POP0TO142016[CE16$DAUID==35251010])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250155] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250155] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
# DA = 35250171
#
finaldf$POP2016[finaldf$DAUID==35250171] <- (CE16$POP2016[CE16$DAUID==35251027] + CE16$POP2016[CE16$DAUID==35251028])
#
finaldf$POP0TO142016[finaldf$DAUID==35250171] <- (CE16$POP0TO142016[CE16$DAUID==35251027] + CE16$POP0TO142016[CE16$DAUID==35251028])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250171] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250171] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
# DA = 35250174
#
finaldf$POP2016[finaldf$DAUID==35250174] <- (CE16$POP2016[CE16$DAUID==35251029] + CE16$POP2016[CE16$DAUID==35251030])
#
finaldf$POP0TO142016[finaldf$DAUID==35250174] <- (CE16$POP0TO142016[CE16$DAUID==35251029] + CE16$POP0TO142016[CE16$DAUID==35251030])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250174] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250174] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
# DA = 35250182
# This was a simple rename to 25350982, except probably the edges changed.
# I'm ingoring minor changes to DA boundaries, because that won't hurt me any more than
# ignoring the ecological fallacy.
#
finaldf$POP2016[finaldf$DAUID==35250182] <- (CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250182] <- (CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250182] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250182] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250982])
#
# DA = 35250187
#
finaldf$POP2016[finaldf$DAUID==35250187] <- (CE16$POP2016[CE16$DAUID==35250985])
#
finaldf$POP0TO142016[finaldf$DAUID==35250187] <- (CE16$POP0TO142016[CE16$DAUID==35250985])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250187] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250985])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250187] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250985])
#
# DA = 35250577
#
finaldf$POP2016[finaldf$DAUID==35250577] <- (CE16$POP2016[CE16$DAUID==35251011] + CE16$POP2016[CE16$DAUID==35251012] + CE16$POP2016[CE16$DAUID==35251013] + CE16$POP2016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$POP0TO142016[finaldf$DAUID==35250577] <- (CE16$POP0TO142016[CE16$DAUID==35251011] + CE16$POP0TO142016[CE16$DAUID==35251012] + CE16$POP0TO142016[CE16$DAUID==35251013] + CE16$POP0TO142016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250577] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250577] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
# DA = 35250584
#
finaldf$POP2016[finaldf$DAUID==35250584] <- (CE16$POP2016[CE16$DAUID==35250998] + CE16$POP2016[CE16$DAUID==35250999])
#
finaldf$POP0TO142016[finaldf$DAUID==35250584] <- (CE16$POP0TO142016[CE16$DAUID==35250998] + CE16$POP0TO142016[CE16$DAUID==35250999])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250584] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250584] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
# DA = 35250653
#
finaldf$POP2016[finaldf$DAUID==35250653] <- (CE16$POP2016[CE16$DAUID==35251016] + CE16$POP2016[CE16$DAUID==35251017] + CE16$POP2016[CE16$DAUID==35251018])
#
finaldf$POP0TO142016[finaldf$DAUID==35250653] <- (CE16$POP0TO142016[CE16$DAUID==35251016] + CE16$POP0TO142016[CE16$DAUID==35251017] + CE16$POP0TO142016[CE16$DAUID==35251018])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250653] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250653] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
# DA = 35250808
#
finaldf$POP2016[finaldf$DAUID==35250808] <- (CE16$POP2016[CE16$DAUID==35251019] + CE16$POP2016[CE16$DAUID==35251020] + CE16$POP2016[CE16$DAUID==35251021])
#
finaldf$POP0TO142016[finaldf$DAUID==35250808] <- (CE16$POP0TO142016[CE16$DAUID==35251019] + CE16$POP0TO142016[CE16$DAUID==35251020] + CE16$POP0TO142016[CE16$DAUID==35251021])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250808] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250808] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
# DA = 35250809
#
finaldf$POP2016[finaldf$DAUID==35250809] <- (CE16$POP2016[CE16$DAUID==35251022] + CE16$POP2016[CE16$DAUID==35251023] + CE16$POP2016[CE16$DAUID==35251024])
#
finaldf$POP0TO142016[finaldf$DAUID==35250809] <- (CE16$POP0TO142016[CE16$DAUID==35251022] + CE16$POP0TO142016[CE16$DAUID==35251023] + CE16$POP0TO142016[CE16$DAUID==35251024])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250809] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250809] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
# DA = 35250840
#
finaldf$POP2016[finaldf$DAUID==35250840] <- (CE16$POP2016[CE16$DAUID==35251025] + CE16$POP2016[CE16$DAUID==35251026])
#
finaldf$POP0TO142016[finaldf$DAUID==35250840] <- (CE16$POP0TO142016[CE16$DAUID==35251025] + CE16$POP0TO142016[CE16$DAUID==35251026])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250840] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250840] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
# DA = 35850841
#
finaldf$POP2016[finaldf$DAUID==35250841] <- (CE16$POP2016[CE16$DAUID==35250990] + CE16$POP2016[CE16$DAUID==35250991] + CE16$POP2016[CE16$DAUID==35250992])
#
finaldf$POP0TO142016[finaldf$DAUID==35250841] <- (CE16$POP0TO142016[CE16$DAUID==35250990] + CE16$POP0TO142016[CE16$DAUID==35250991] + CE16$POP0TO142016[CE16$DAUID==35250992])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250841] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250841] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
# DA = 35250842
#
finaldf$POP2016[finaldf$DAUID==35250842] <- (CE16$POP2016[CE16$DAUID==35250986] + CE16$POP2016[CE16$DAUID==35250987])
#
finaldf$POP0TO142016[finaldf$DAUID==35250842] <- (CE16$POP0TO142016[CE16$DAUID==35250986] + CE16$POP0TO142016[CE16$DAUID==35250987])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250842] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250842] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
# DA = 35250844
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250858
# 
finaldf$POP2016[finaldf$DAUID==35250858] <- (CE16$POP2016[CE16$DAUID==35251000] + CE16$POP2016[CE16$DAUID==35251001] + CE16$POP2016[CE16$DAUID==35251002])
#
finaldf$POP0TO142016[finaldf$DAUID==35250858] <- (CE16$POP0TO142016[CE16$DAUID==35251000] + CE16$POP0TO142016[CE16$DAUID==35251001] + CE16$POP0TO142016[CE16$DAUID==35251002])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250858] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250858] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
# DA = 35250915
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income too, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250916
# this next one's a monster, it got split into 6 DAs by 2016!
#
finaldf$POP2016[finaldf$DAUID==35250916] <- (CE16$POP2016[CE16$DAUID==35251033] + CE16$POP2016[CE16$DAUID==35251035] + CE16$POP2016[CE16$DAUID==35251036] + CE16$POP2016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$POP0TO142016[finaldf$DAUID==35250916] <- (CE16$POP0TO142016[CE16$DAUID==35251033] + CE16$POP0TO142016[CE16$DAUID==35251035] + CE16$POP0TO142016[CE16$DAUID==35251036] + CE16$POP0TO142016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250916] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250916] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
# DA = 35250917
#
finaldf$POP2016[finaldf$DAUID==35250917] <- (CE16$POP2016[CE16$DAUID==35250996] + CE16$POP2016[CE16$DAUID==35250997])
#
finaldf$POP0TO142016[finaldf$DAUID==35250917] <- (CE16$POP0TO142016[CE16$DAUID==35250996] + CE16$POP0TO142016[CE16$DAUID==35250997])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250917] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250917] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
# DA = 35250926
#
finaldf$POP2016[finaldf$DAUID==35250926] <- (CE16$POP2016[CE16$DAUID==35250976] + CE16$POP2016[CE16$DAUID==35250980])
#
finaldf$POP0TO142016[finaldf$DAUID==35250926] <- (CE16$POP0TO142016[CE16$DAUID==35250976] + CE16$POP0TO142016[CE16$DAUID==35250980])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250926] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250926] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
# DA = 35250927
#
finaldf$POP2016[finaldf$DAUID==35250927] <- (CE16$POP2016[CE16$DAUID==35250978])
#
finaldf$POP0TO142016[finaldf$DAUID==35250927] <- (CE16$POP0TO142016[CE16$DAUID==35250978])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250927] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250978])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250927] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250978])
#
# now we have to strip out all DAs with NA for 2016 data
#
finaldf <- subset(finaldf, !is.na(AVGAFTERTAXINCHH2016))
finaldf <- subset(finaldf, !is.na(PERCLOWINC0TO52016))
finaldf <- subset(finaldf, AVGAFTERTAXINCHH2016>0)
#
# calculate delta income, and the flag for delta income above or below city weighted average value
#
finaldf$deltaincome <- finaldf$AVGAFTERTAXINCHH2016/finaldf$AVGAFTERTAXINCHH2006
finaldf$deltaincoveravg <- as.integer(finaldf$deltaincome > finaldf$deltaincome[finaldf$DAUID==3525])
#
# calculate delta pop 0 to 14
#
finaldf$deltapop0to14 <- finaldf$POP0TO142016 - finaldf$POP0TO142006
```

## Flagging DAs for school closure

An incomplete set of shapefiles was received from the HWDSB for primary, middle school, and secondary school catchments from the years 2005 to 2019; this set of files was checked for veracity against the archive of the HWDSB website available at archive.org, as well as against news reports of school closures throughout that period, to produce a complete and checked set of HWDSB school catchment GIS files. For this paper, the 2005-6 primary-school catchment file was then modified to add a flag for all primary school catchments where the primary school was subsequently closed by 2016.

A spatial join was then done in ArcGIS between the flagged 2006 HWDSB elementary school catchment file and the 2006 dissemination area shapefile, in order to add a flag to each 2006 DA to identify whether its public school had closed by 2016. The file created was then manually verified for the condition of each DA, and a flag was created for each DA to identify whether it was (mostly or completely) inside the catchment of a subsequently closed school. The resulting map, showing wwhich Hamilton DAs experienced a school closure between 2006 and 2016, is shown in Figure \ref{fig:DA-map}. (Note that the closure of Bell Stone school in south Glanbrook is not shown, in order to show more detail for the rest of the city.)


```{r load-geometry, include=FALSE}
#
# load the public school DA geometry file, join it to census file
#
DAgeometry <- st_read("./ArcGIS", layer = "Join_Output")
DAgeometry <- mutate(DAgeometry, DAUID = as.integer(as.character(DAUID)))
DAs <- DAgeometry %>%
select(DAUID, Max_CLOSED, geometry)
DAsj <- inner_join(DAs, finaldf)
DAsj$Isschoolclosed <- as.numeric(DAsj$Max_CLOSED==1 | DAsj$Max_CLOSED==2)
```

For Catholic school closures, the same work was performed in ArcGIS: a spatial join was performed between closed Catholic elementary catchments and DAs, and it was manually verified. In the case of Catholic schools, however, lack of hard data between 2006 and 2010 meant that some pre-2010 boundaries had to be assumed. The map showing which Hamilton DAs experienced a Catholic primary school closure from 2006 to 2016 is shown in Figure \ref{fig:Cath-map}.

```{r print-DA-map, echo = FALSE, warning = FALSE, fig.cap="\\label{fig:DA-map} map of DAs with public primary school closures"}
ham_bb <- st_bbox(DAsj %>% filter(DAUID %in% c("35250267", "35250942")))
#new tmap with bbox
tm_shape(DAsj, bbox = ham_bb) + 
tm_borders() +
   tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
#          legend.position = c("top","right"),
          legend.bg.alpha = 1) +       
   tm_polygons(col = "Isschoolclosed", title="School Status",
               style = "fixed",
              breaks = c(0, 0.9, 2),
              labels = c("Not Closed", "Closed")
               )
```


```{r load-Catholic, include=FALSE}
DAcath <- st_read("./ArcGIS/CATHOLIC", layer = "Join_Cath")
DAcath <- mutate(DAcath, DAUID = as.integer(as.character(DAUID)))
DAcath <- DAcath %>% 
  rename(
    Cath_CLOSED = Max_CLOSED
    )
st_geometry(DAcath) <- NULL
DAcath <- DAcath %>% select(DAUID, Cath_CLOSED)
DAsj2 <- inner_join(DAsj, DAcath)
DAsj2$Isschoolclosed2 <- as.numeric(DAsj2$Cath_CLOSED==1 | DAsj2$Cath_CLOSED==2)
```


```{r print-Cath-map, echo = FALSE, warning = FALSE, fig.cap="\\label{fig:Cath-map} Map of DAs with Catholic primary school closures"}
#new tmap with bbox
tm_shape(DAsj2, bbox = ham_bb) + 
tm_borders() +
   tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
#          legend.position = c("top","right"),
          legend.bg.alpha = 1) +       
   tm_polygons(col = "Isschoolclosed2", title="School Status",
               style = "fixed",
              breaks = c(0, 0.9, 2),
              labels = c("Not Closed", "Closed")
               )
```


Exploratory Analysis
====================

An initial investigation can use density plots to determine whether there is a difference in catchments, between those with a school closure and those without, for various variables in the census data. In Figure \ref{fig:densityplots}, for example, it can be seen that for both the HWDSB and HWCDSB, schools from catchments with a lower average after-tax household income were more likely to be closed; this, however, could certainly be due to the difference in incomes across Hamilton, since areas seeing housing growth (and thus high utilization of schools) are less likely to see school closures, while older areas with no housing growth (and thus possible under-utilization of schools that were built for a larger child population) would be more likely to see schools close. Contrast this with the density plots for DA delta income in Figure \ref{fig:deltaincomeplots}, for example: neighbourhoods showing lower income growth from 2006 to 2016 seem to be marginally _less_ likely to see their school close.


```{r fig-right-left-panel-plot, echo = FALSE, warning = FALSE, fig.cap="\\label{fig:densityplots} Income characterists of closed and non-closed DAs"}
# Recreate Figure 1
a <- ggplot(DAsj, aes(x = AVGAFTERTAXINCHH2006))
a <- a + geom_density(aes(color = as.factor(Isschoolclosed))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Public schools",x="DA 2006 average income", y = "Density", col="School Closed")
a <- a + theme(legend.position="bottom") 
#
b <- ggplot(DAsj2, aes(x = AVGAFTERTAXINCHH2006))
b <- b + geom_density(aes(color = as.factor(Isschoolclosed2))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Catholic schools",x="DA 2006 average income", y = "Density", col="School Closed")
b <- b + theme(legend.position="bottom")
grid.arrange(a, b, ncol = 2)
```


```{r fig-right-left-panel-plot2, echo = FALSE, warning = FALSE, fig.cap="\\label{fig:deltaincomeplots} Delta income characterists of closed and non-closed DAs"}
# Recreate Figure 
c <- ggplot(DAsj, aes(x = (deltaincome)))
c <- c + geom_density(aes(color = as.factor(Isschoolclosed))) +  xlim(NA,2.5) +
  geom_vline(aes(xintercept = mean(deltapop0to14)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Public schools",x="DA delta income (%)", y = "Density", col="School closed")
c <- c + theme(legend.position="bottom") 
#
d <- ggplot(DAsj2, aes(x = (deltaincome)))
d <- d + geom_density(aes(color = as.factor(Isschoolclosed2))) + xlim(NA,2.5) +
  geom_vline(aes(xintercept = mean(deltapop0to14)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Catholic schools",x="DA delta income (%)", y = "Density", col="School closed")
d <- d + theme(legend.position="bottom")
grid.arrange(c, d, ncol = 2)
```


Probit Analysis
===============

A probit of the form

$$
Pr(Y=1 | X) = \Phi(X^T\beta)
$$

can be used to determine whether or not any socioeconomic factors for a DA are correlated with the binary outcome of school closure. In this case, Y is a vector of binary (1/0) flags for school closure, $X$ is a vector of socioeconomic characteristics for each DA, and $\beta$ is the coefficient vector to be solved.

Two separate probit regressions were performed using _glm_ in R, using a limited set of socioeconomic characteristics from the 2006 and 2016 census, to determine whether school closure was more likely to happen in DAs with certain socioeconomic characteristics. The variables used in the probit regressions for this paper are shown in Table \ref{tab:probitvars}; regression results for both Catholic and Public schools are compared in Table \ref{tab:probitresults}.

```{r table1-create, echo = FALSE}
table0.df <- data.frame(Variable = c("deltaincome", "deltapop0to14", "POP0TO142006", "log(AVGAFTERTAXINCHH2006)", "PERCLOWINC0TO52006"),
                      Meaning = c("percent change in DA average aftertax household income, 2006-2016", 
                           "absolute change in child (0-14) population, 2006-2016", 
                           "child (0-14) population, 2006", 
                           "natural log of 2006 average after-tax household income", 
                           "percent of children 0-5 under family low-income threshold, 2006"))
kable(table0.df, caption = "\\label{tab:probitvars} Regression variables used") %>% kable_styling(latex_options = c("scale_down"))
```


```{r pprobit, include = FALSE}
Pprobit <- glm(Isschoolclosed ~ deltaincome + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj)
summary(Pprobit)
```

```{r cprobit, include = FALSE}
Cprobit <- glm(Isschoolclosed2 ~ deltaincome + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj2)
summary(Cprobit)
```


```{r probitresults, echo=FALSE}
models.df <- data.frame(Estimate.1 = Pprobit$coefficients, 
                        pval.1 = paste(ifelse(summary(Pprobit)$coefficients[,4] > 0.001, 
                                              round(summary(Pprobit)$coefficients[,4], 3), 
                                              "< 0.001")),
                        Estimate.2 = Cprobit$coefficients, 
                        pval.2 = paste(ifelse(summary(Cprobit)$coefficients[,4] > 0.001, 
                                              round(summary(Cprobit)$coefficients[,4], 3), 
                                              "< 0.001")))

kable(models.df,
      digits = 3,
      booktabs = TRUE,
      escape = FALSE,
      col.names = c("$\\beta$", "p-val", "$\\beta$", "p-val"),
      caption = "\\label{tab:probitresults} Regression results: Likelihood of school closure") %>%
  add_header_above(c("Variable" = 1, 
                     "Public" = 2, 
                     "Catholic" = 2),
                   escape = FALSE) %>%
  footnote(c(paste("AIC (Public) = ", as.character(round(summary(Pprobit)$aic, 2))),
             paste("AIC (Catholic) = ", as.character(round(summary(Cprobit)$aic, 2)))),
           escape = FALSE)


```

Discussion
==========

As can be seen in Table \ref{tab:probitresults}, there is a significant negative relationship between 2006 household after-tax income and likelihood of public or Catholic primary school closure in Hamilton. This may be simply due to most school closures taking place in the older lower city where lower income housing is prevalent; newer areas of the city, which have more expensive houses and thus would require a higher after-tax income for residents, have seen net new construction of schools, with only a few school closures taking place south of the Lincoln Alexander Parkway. 

The difference in Catholic and public regressions, for the variable of delta income, is an interesting result; Figures \ref{fig:DA-map} and \ref{fig:Cath-map} show a locational difference in lower-city Catholic and public closures, with closed Catholic schools more likely to be located south of King Street, with closed public schools more likely to occur in the north end of the city. The significance of delta income for the public, and not Catholic, board may thus be an artifact of the gentrification that took place in the North End over the study period.

Since the public board combined lower-city school closures with rebuilding of several lower-city schools, a road to further understanding would be to conduct a regression of school age on the socioeconomic variables used in this paper, to illustrate whether longer walking distances to schools caused by HWDSB closures may have been offset by an improvement in the capital stock of lower-city schools. Another interesting study would involve seeing whether school age correlates positively with per-student education costs, to determine if the economic efficiency of education is affected by building age; this would require finding per-student education costs for each school.


References {#references .unnumbered}
==========