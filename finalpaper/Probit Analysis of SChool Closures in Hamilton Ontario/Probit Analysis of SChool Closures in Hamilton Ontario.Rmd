---
title: Probit Analysis of School Closures in Hamilton Ontario
author:
  - name: John Merrall
    email: merralja@mcmaster.ca
    affiliation: School of Geography and Earth Sciences, McMaster University
    footnote: Corresponding Author
address:
  - code: School of Geography and Earth Sciences, McMaster University
    address: General Sciences Rm. 206, McMaster University, 1280 Main Street West, Hamilton, Ontario L8S 4K1
abstract: |
  This is the abstract.

  It consists of two paragraphs.

journal: "Journal for the Society for Putting Things on Top of Other Things"
date: "`r Sys.Date()`"
bibliography: mybibfile.bib
#linenumbers: true
#numbersections: true
csl: elsevier-harvard.csl
output: rticles::elsevier_article
---

_Text based on elsarticle sample manuscript, see [http://www.elsevier.com/author-schemas/latex-instructions#elsarticle](http://www.elsevier.com/author-schemas/latex-instructions#elsarticle)_


```{r load-packages, include = FALSE}
library(dplyr)
library(ggplot2)
library(kableExtra)
library(rticles)
library(sf)
library(tidyverse)
library(tmap)
```


Introduction
============

School closures in the city of Hamilton became a contentious issue in 2002, when the Harris government appointed Jim Murray as special supervisor to oversee a rationalization of the Hamilton-Wentworth District School Board (HWDSB) in the face of trustee opposition to closure of under-utilized schools (Honey 2002; Prokaska 2012). The following years saw a wave of public board school closures and replacements in Hamilton, aiming to reduce per-pupil education costs in the face of urban demographic change, and to access new provincial construction funding. Resistance to the consolidation process eventually relented, and this accommodation review system has since become institutionalized at the HWDSB; the Hamilton Catholic board (HWCDSB), facing similar overcapacity issues, has followed suit.

Given the wave of school reorganizations that occurred over the past twenty years, it makes sense to look at whether these closures had a social equity effect: neighbourhoods certainly didn't suddenly find themselves without any school at all, but distance to schools would have increased in areas where school closures occurred. Did this increase in walking distance disproportionately affect the poor?

This paper will examine the likelihood of a HWDSB or HWCDSB school being closed between the years of 2006 and 2016, dependent on the income and deprivation characteristics and trends of each census dissemination area over that same period of time. 


Data
====

## Census Data

```{r load-census, include = FALSE}
#
# here we are loading 2006 and 2016 DA-level census data which has been downloaded from CHASS.
#
CENSUS2006DATA <- read.csv(file="CENSUS2006DATA.csv", header=TRUE, sep=",")
CENSUS2016DATA <- read.csv(file="CENSUS2016DATA.csv", header=TRUE, sep=",")
#
# the problem with using this data is that we will have a fair number of NAs.
# we subset out the NA data here:
#
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(AVGAFTERTAXINC))
CENSUS2006DATA <- subset(CENSUS2006DATA, !is.na(PERCLOWINC0TO5))
#
# for some weird reason, there's also areas with 0 reported average after tax income.
# I guess I can't use those in my work either, if I want to calculate delta incomes!
# So they have to go as well.
#
CENSUS2006DATA <- subset(CENSUS2006DATA, AVGAFTERTAXINC>0)
#
# and trim excess columns
#
CENSUS2006DATA <- CENSUS2006DATA %>% select(DAUID, POP2006, POP0TO14ADD, PERCLOWINC0TO5, AVGAFTERTAXINC)
```

First, a compact set of Hamilton dissemination area level census data and GIS dissemination area shapefiles for census years 2006 and 2016 were downloaded from CHASS; areas with NA or zero values for Average After-Tax Income, and NA values for Percent Children 0-5 Low Income, were dropped from the dataset. Since this paper's analysis is performed at the 2006 dissemination area level of support, 2016 data was appended to the 2006 data frame; the 23 dissemination areas of 2006 which were split by the time of the 2016 census were identified in R, verified manually in ArcGIS, and 2016 data was then manipulated to append to the data frames for those subsequently-split 2006 DAs. Then, the 2006 and 2016 data was used to calculate each DA's percent change in average household after-tax income, and absolute change in population ages 0 to 14. 

```{r data-preparation, include=FALSE}
#
# renaming files and columns to make following the code easier:
#
CE06 <- CENSUS2006DATA %>% 
  rename(
    POP0TO142006 = POP0TO14ADD,
    PERCLOWINC0TO52006 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2006 = AVGAFTERTAXINC
    )
CE16 <- CENSUS2016DATA %>%
  rename(
    POP0TO142016 = POP0TO14,
    PERCLOWINC0TO52016 = PERCLOWINC0TO5,
    AVGAFTERTAXINCHH2016 = AVGAFTERTAXINCOME
  )
#
# find split DAs - this code can be run and the data frame inspected if you wish
#
in2006not2016 <- anti_join(CE06,CE16)
#
# this next bit of code is a doozy
#
# the default for "merge" will do a join while dropping 2006 DAs found in in2006not2016
# so we have to keep those by saying all.x = "TRUE"
# it also has no problem bringing "NA" data from 2016
# so we will have to drop those later on
#
finaldf <- merge(CE06, CE16, by = "DAUID", all.x = "TRUE")
# now we add in all the split-DA data by hand
# ONE AT A TIME
#
# DAUID==35250063
#
finaldf$POP2016[finaldf$DAUID==35250063] <- (CE16$POP2016[CE16$DAUID==35250999] + CE16$POP2016[CE16$DAUID==35250998])
#
finaldf$POP0TO142016[finaldf$DAUID==35250063] <- (CE16$POP0TO142016[CE16$DAUID==35250999] + CE16$POP0TO142016[CE16$DAUID==35250998])
#
# this is a bit kludged, I should have downloaded number of households to average this 
# by household instead of by population.
# could fix it later
# (though these are all new neighbourhoods, so we can assume in approximation that all the
# households are homogeneous in size)
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250063] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
#
# and for perclowinc0to5, this really does just take population proportions to solve
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250063] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998]) / finaldf$POP2016[finaldf$DAUID==35250063]), 0
)
# 
# now we just have to do this for the other 22 split DAs
#
# then we delete all the data that is NA for 2016
#
# so let's do all the rest here.
#
# DA = 35250132
#
finaldf$POP2016[finaldf$DAUID==35250132] <- (CE16$POP2016[CE16$DAUID==35250981] + CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250132] <- (CE16$POP0TO142016[CE16$DAUID==35250981] + CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250132] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250132] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250981] * CE16$POP2016[CE16$DAUID==35250981] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250982] * CE16$POP2016[CE16$DAUID==35250982]) / finaldf$POP2016[finaldf$DAUID==35250132]), 0
)
#
# DA = 35250154
#
finaldf$POP2016[finaldf$DAUID==35250154] <- (CE16$POP2016[CE16$DAUID==35251003] + CE16$POP2016[CE16$DAUID==35251004] + CE16$POP2016[CE16$DAUID==35251005] + CE16$POP2016[CE16$DAUID==35251006])
#
finaldf$POP0TO142016[finaldf$DAUID==35250154] <- (CE16$POP0TO142016[CE16$DAUID==35251003] + CE16$POP0TO142016[CE16$DAUID==35251004] + CE16$POP0TO142016[CE16$DAUID==35251005] + CE16$POP0TO142016[CE16$DAUID==35251006])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250154] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250154] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251003] * CE16$POP2016[CE16$DAUID==35251003] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251004] * CE16$POP2016[CE16$DAUID==35251004] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251005] * CE16$POP2016[CE16$DAUID==35251005] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251006] * CE16$POP2016[CE16$DAUID==35251006]) / finaldf$POP2016[finaldf$DAUID==35250154]), 0
)
#
# DA = 35250155
#
finaldf$POP2016[finaldf$DAUID==35250155] <- (CE16$POP2016[CE16$DAUID==35251007] + CE16$POP2016[CE16$DAUID==35251008] + CE16$POP2016[CE16$DAUID==35251009] + CE16$POP2016[CE16$DAUID==35251010])
#
finaldf$POP0TO142016[finaldf$DAUID==35250155] <- (CE16$POP0TO142016[CE16$DAUID==35251007] + CE16$POP0TO142016[CE16$DAUID==35251008] + CE16$POP0TO142016[CE16$DAUID==35251009] + CE16$POP0TO142016[CE16$DAUID==35251010])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250155] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250155] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251007] * CE16$POP2016[CE16$DAUID==35251007] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251008] * CE16$POP2016[CE16$DAUID==35251008] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251009] * CE16$POP2016[CE16$DAUID==35251009] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251010] * CE16$POP2016[CE16$DAUID==35251010]) / finaldf$POP2016[finaldf$DAUID==35250155]), 0
)
#
# DA = 35250171
#
finaldf$POP2016[finaldf$DAUID==35250171] <- (CE16$POP2016[CE16$DAUID==35251027] + CE16$POP2016[CE16$DAUID==35251028])
#
finaldf$POP0TO142016[finaldf$DAUID==35250171] <- (CE16$POP0TO142016[CE16$DAUID==35251027] + CE16$POP0TO142016[CE16$DAUID==35251028])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250171] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250171] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251027] * CE16$POP2016[CE16$DAUID==35251027] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251028] * CE16$POP2016[CE16$DAUID==35251028]) / finaldf$POP2016[finaldf$DAUID==35250171]), 0
)
#
# DA = 35250174
#
finaldf$POP2016[finaldf$DAUID==35250174] <- (CE16$POP2016[CE16$DAUID==35251029] + CE16$POP2016[CE16$DAUID==35251030])
#
finaldf$POP0TO142016[finaldf$DAUID==35250174] <- (CE16$POP0TO142016[CE16$DAUID==35251029] + CE16$POP0TO142016[CE16$DAUID==35251030])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250174] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250174] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251029] * CE16$POP2016[CE16$DAUID==35251029] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251030] * CE16$POP2016[CE16$DAUID==35251030]) / finaldf$POP2016[finaldf$DAUID==35250174]), 0
)
#
# DA = 35250182
# This was a simple rename to 25350982, except probably the edges changed.
# I'm ingoring minor changes to DA boundaries, because that won't hurt me any more than
# ignoring the ecological fallacy.
#
finaldf$POP2016[finaldf$DAUID==35250182] <- (CE16$POP2016[CE16$DAUID==35250982])
#
finaldf$POP0TO142016[finaldf$DAUID==35250182] <- (CE16$POP0TO142016[CE16$DAUID==35250982])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250182] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250982])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250182] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250982])
#
# DA = 35250187
#
finaldf$POP2016[finaldf$DAUID==35250187] <- (CE16$POP2016[CE16$DAUID==35250985])
#
finaldf$POP0TO142016[finaldf$DAUID==35250187] <- (CE16$POP0TO142016[CE16$DAUID==35250985])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250187] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250985])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250187] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250985])
#
# DA = 35250577
#
finaldf$POP2016[finaldf$DAUID==35250577] <- (CE16$POP2016[CE16$DAUID==35251011] + CE16$POP2016[CE16$DAUID==35251012] + CE16$POP2016[CE16$DAUID==35251013] + CE16$POP2016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$POP0TO142016[finaldf$DAUID==35250577] <- (CE16$POP0TO142016[CE16$DAUID==35251011] + CE16$POP0TO142016[CE16$DAUID==35251012] + CE16$POP0TO142016[CE16$DAUID==35251013] + CE16$POP0TO142016[CE16$DAUID==35251014] + CE16$POP2016[CE16$DAUID==35251015])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250577] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250577] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251011] * CE16$POP2016[CE16$DAUID==35251011] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251012] * CE16$POP2016[CE16$DAUID==35251012] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251013] * CE16$POP2016[CE16$DAUID==35251013] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251014] * CE16$POP2016[CE16$DAUID==35251014] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251015] * CE16$POP2016[CE16$DAUID==35251015]) / finaldf$POP2016[finaldf$DAUID==35250577]), 0
)
#
# DA = 35250584
#
finaldf$POP2016[finaldf$DAUID==35250584] <- (CE16$POP2016[CE16$DAUID==35250998] + CE16$POP2016[CE16$DAUID==35250999])
#
finaldf$POP0TO142016[finaldf$DAUID==35250584] <- (CE16$POP0TO142016[CE16$DAUID==35250998] + CE16$POP0TO142016[CE16$DAUID==35250999])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250584] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250584] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250998] * CE16$POP2016[CE16$DAUID==35250998] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250999] * CE16$POP2016[CE16$DAUID==35250999]) / finaldf$POP2016[finaldf$DAUID==35250584]), 0
)
#
# DA = 35250653
#
finaldf$POP2016[finaldf$DAUID==35250653] <- (CE16$POP2016[CE16$DAUID==35251016] + CE16$POP2016[CE16$DAUID==35251017] + CE16$POP2016[CE16$DAUID==35251018])
#
finaldf$POP0TO142016[finaldf$DAUID==35250653] <- (CE16$POP0TO142016[CE16$DAUID==35251016] + CE16$POP0TO142016[CE16$DAUID==35251017] + CE16$POP0TO142016[CE16$DAUID==35251018])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250653] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250653] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251016] * CE16$POP2016[CE16$DAUID==35251016] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251017] * CE16$POP2016[CE16$DAUID==35251017] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251018] * CE16$POP2016[CE16$DAUID==35251018]) / finaldf$POP2016[finaldf$DAUID==35250653]), 0
)
#
# DA = 35250808
#
finaldf$POP2016[finaldf$DAUID==35250808] <- (CE16$POP2016[CE16$DAUID==35251019] + CE16$POP2016[CE16$DAUID==35251020] + CE16$POP2016[CE16$DAUID==35251021])
#
finaldf$POP0TO142016[finaldf$DAUID==35250808] <- (CE16$POP0TO142016[CE16$DAUID==35251019] + CE16$POP0TO142016[CE16$DAUID==35251020] + CE16$POP0TO142016[CE16$DAUID==35251021])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250808] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250808] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251019] * CE16$POP2016[CE16$DAUID==35251019] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251020] * CE16$POP2016[CE16$DAUID==35251020] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251021] * CE16$POP2016[CE16$DAUID==35251021]) / finaldf$POP2016[finaldf$DAUID==35250808]), 0
)
#
# DA = 35250809
#
finaldf$POP2016[finaldf$DAUID==35250809] <- (CE16$POP2016[CE16$DAUID==35251022] + CE16$POP2016[CE16$DAUID==35251023] + CE16$POP2016[CE16$DAUID==35251024])
#
finaldf$POP0TO142016[finaldf$DAUID==35250809] <- (CE16$POP0TO142016[CE16$DAUID==35251022] + CE16$POP0TO142016[CE16$DAUID==35251023] + CE16$POP0TO142016[CE16$DAUID==35251024])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250809] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250809] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251022] * CE16$POP2016[CE16$DAUID==35251022] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251023] * CE16$POP2016[CE16$DAUID==35251023] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251024] * CE16$POP2016[CE16$DAUID==35251024]) / finaldf$POP2016[finaldf$DAUID==35250809]), 0
)
#
# DA = 35250840
#
finaldf$POP2016[finaldf$DAUID==35250840] <- (CE16$POP2016[CE16$DAUID==35251025] + CE16$POP2016[CE16$DAUID==35251026])
#
finaldf$POP0TO142016[finaldf$DAUID==35250840] <- (CE16$POP0TO142016[CE16$DAUID==35251025] + CE16$POP0TO142016[CE16$DAUID==35251026])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250840] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250840] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251025] * CE16$POP2016[CE16$DAUID==35251025] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251026] * CE16$POP2016[CE16$DAUID==35251026]) / finaldf$POP2016[finaldf$DAUID==35250840]), 0
)
#
# DA = 35850841
#
finaldf$POP2016[finaldf$DAUID==35250841] <- (CE16$POP2016[CE16$DAUID==35250990] + CE16$POP2016[CE16$DAUID==35250991] + CE16$POP2016[CE16$DAUID==35250992])
#
finaldf$POP0TO142016[finaldf$DAUID==35250841] <- (CE16$POP0TO142016[CE16$DAUID==35250990] + CE16$POP0TO142016[CE16$DAUID==35250991] + CE16$POP0TO142016[CE16$DAUID==35250992])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250841] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250841] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250990] * CE16$POP2016[CE16$DAUID==35250990] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250991] * CE16$POP2016[CE16$DAUID==35250991] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250992] * CE16$POP2016[CE16$DAUID==35250992]) / finaldf$POP2016[finaldf$DAUID==35250841]), 0
)
#
# DA = 35250842
#
finaldf$POP2016[finaldf$DAUID==35250842] <- (CE16$POP2016[CE16$DAUID==35250986] + CE16$POP2016[CE16$DAUID==35250987])
#
finaldf$POP0TO142016[finaldf$DAUID==35250842] <- (CE16$POP0TO142016[CE16$DAUID==35250986] + CE16$POP0TO142016[CE16$DAUID==35250987])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250842] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250842] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250986] * CE16$POP2016[CE16$DAUID==35250986] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250987] * CE16$POP2016[CE16$DAUID==35250987]) / finaldf$POP2016[finaldf$DAUID==35250842]), 0
)
#
# DA = 35250844
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250858
# 
finaldf$POP2016[finaldf$DAUID==35250858] <- (CE16$POP2016[CE16$DAUID==35251000] + CE16$POP2016[CE16$DAUID==35251001] + CE16$POP2016[CE16$DAUID==35251002])
#
finaldf$POP0TO142016[finaldf$DAUID==35250858] <- (CE16$POP0TO142016[CE16$DAUID==35251000] + CE16$POP0TO142016[CE16$DAUID==35251001] + CE16$POP0TO142016[CE16$DAUID==35251002])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250858] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250858] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251000] * CE16$POP2016[CE16$DAUID==35251000] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251001] * CE16$POP2016[CE16$DAUID==35251001] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251002] * CE16$POP2016[CE16$DAUID==35251002]) / finaldf$POP2016[finaldf$DAUID==35250858]), 0
)
#
# DA = 35250915
#
# Unfortunately, one of the 2016 DAs that makes this up has an NA for income too, so we'll
# skip this one and strip it when we strip 2016 NAs at the end
#
# DA = 35250916
# this next one's a monster, it got split into 6 DAs by 2016!
#
finaldf$POP2016[finaldf$DAUID==35250916] <- (CE16$POP2016[CE16$DAUID==35251033] + CE16$POP2016[CE16$DAUID==35251035] + CE16$POP2016[CE16$DAUID==35251036] + CE16$POP2016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$POP0TO142016[finaldf$DAUID==35250916] <- (CE16$POP0TO142016[CE16$DAUID==35251033] + CE16$POP0TO142016[CE16$DAUID==35251035] + CE16$POP0TO142016[CE16$DAUID==35251036] + CE16$POP0TO142016[CE16$DAUID==35251037] + CE16$POP2016[CE16$DAUID==35251038] + CE16$POP2016[CE16$DAUID==35251039])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250916] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250916] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35251033] * CE16$POP2016[CE16$DAUID==35251033] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251035] * CE16$POP2016[CE16$DAUID==35251035] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251036] * CE16$POP2016[CE16$DAUID==35251036] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251037] * CE16$POP2016[CE16$DAUID==35251037] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251038] * CE16$POP2016[CE16$DAUID==35251038] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35251039] * CE16$POP2016[CE16$DAUID==35251039]) / finaldf$POP2016[finaldf$DAUID==35250916]), 0
)
#
# DA = 35250917
#
finaldf$POP2016[finaldf$DAUID==35250917] <- (CE16$POP2016[CE16$DAUID==35250996] + CE16$POP2016[CE16$DAUID==35250997])
#
finaldf$POP0TO142016[finaldf$DAUID==35250917] <- (CE16$POP0TO142016[CE16$DAUID==35250996] + CE16$POP0TO142016[CE16$DAUID==35250997])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250917] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250917] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250996] * CE16$POP2016[CE16$DAUID==35250996] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250997] * CE16$POP2016[CE16$DAUID==35250997]) / finaldf$POP2016[finaldf$DAUID==35250917]), 0
)
#
# DA = 35250926
#
finaldf$POP2016[finaldf$DAUID==35250926] <- (CE16$POP2016[CE16$DAUID==35250976] + CE16$POP2016[CE16$DAUID==35250980])
#
finaldf$POP0TO142016[finaldf$DAUID==35250926] <- (CE16$POP0TO142016[CE16$DAUID==35250976] + CE16$POP0TO142016[CE16$DAUID==35250980])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250926] <-     round(((CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250926] <-     round(((CE16$PERCLOWINC0TO5[CE16$DAUID==35250976] * CE16$POP2016[CE16$DAUID==35250976] + CE16$PERCLOWINC0TO52016[CE16$DAUID==35250980] * CE16$POP2016[CE16$DAUID==35250980]) / finaldf$POP2016[finaldf$DAUID==35250926]), 0
)
#
# DA = 35250927
#
finaldf$POP2016[finaldf$DAUID==35250927] <- (CE16$POP2016[CE16$DAUID==35250978])
#
finaldf$POP0TO142016[finaldf$DAUID==35250927] <- (CE16$POP0TO142016[CE16$DAUID==35250978])
#
finaldf$AVGAFTERTAXINCHH2016[finaldf$DAUID==35250927] <-     (CE16$AVGAFTERTAXINCHH2016[CE16$DAUID==35250978])
#
finaldf$PERCLOWINC0TO52016[finaldf$DAUID==35250927] <- (CE16$PERCLOWINC0TO5[CE16$DAUID==35250978])
#
# now we have to strip out all DAs with NA for 2016 data
#
finaldf <- subset(finaldf, !is.na(AVGAFTERTAXINCHH2016))
finaldf <- subset(finaldf, !is.na(PERCLOWINC0TO52016))
finaldf <- subset(finaldf, AVGAFTERTAXINCHH2016>0)
#
# calculate delta income, and the flag for delta income above or below city weighted average value
#
finaldf$deltaincome <- finaldf$AVGAFTERTAXINCHH2016/finaldf$AVGAFTERTAXINCHH2006
finaldf$deltaincoveravg <- as.integer(finaldf$deltaincome > finaldf$deltaincome[finaldf$DAUID==3525])
#
# calculate delta pop 0 to 14
#
finaldf$deltapop0to14 <- finaldf$POP0TO142016 - finaldf$POP0TO142006
```

## Flagging DAs for school closure

An incomplete set of shapefiles was received from the HWDSB for primary, middle school, and secondary school catchments from the years 2005 to 2019; this set of files was checked for veracity against the archive of the HWDSB website available at archive.org, as well as against news reports of school closures throughout that period, to produce a complete and checked set of HWDSB school catchment GIS files. For this paper, the 2005-6 primary-school catchment file was then modified to add a flag for all primary school catchments where the primary school was subsequently closed by 2016.

A spatial join was then done in ArcGIS between the flagged 2006 HWDSB elementary school catchment file and the 2006 dissemination area shapefile, in order to add a flag to each 2006 DA to identify whether its public school had closed by 2016. The file created was then manually verified for the condition of each DA, and a flag was created for each DA to identify whether it was (mostly or completely) inside the catchment of a subsequently closed school. The resulting map, showing wwhich Hamilton DAs experienced a school closure between 2006 and 2016, is shown in Figure \ref{fig:DA-map}. (Note that the closure of Bell Stone school in south Glanbrook is not shown, in order to show more detail for the rest of the city.)


```{r load-geometry, include=FALSE}
#
# load the public school DA geometry file, join it to census file
#
DAgeometry <- st_read("./ArcGIS", layer = "Join_Output")
DAgeometry <- mutate(DAgeometry, DAUID = as.integer(as.character(DAUID)))
DAs <- DAgeometry %>%
select(DAUID, Max_CLOSED, geometry)
DAsj <- inner_join(DAs, finaldf)
DAsj$Isschoolclosed <- as.numeric(DAsj$Max_CLOSED==1 | DAsj$Max_CLOSED==2)
```

For Catholic school closures, the same work was performed in ArcGIS: a spatial join was performed between closed Catholic elementary catchments and DAs, and it was manually verified. In the case of Catholic schools, however, lack of hard data between 2006 and 2010 meant that some pre-2010 boundaries had to be assumed. The map showing which Hamilton DAs experienced a Catholic primary school closure from 2006 to 2016 is shown in Figure \ref{fig:Cath-map}.

```{r print-DA-map, echo = FALSE, fig.cap="\\label{fig:DA-map} map of DAs with public primary school closures"}
ham_bb <- st_bbox(DAsj %>% filter(DAUID %in% c("35250267", "35250942")))
#new tmap with bbox
tm_shape(DAsj, bbox = ham_bb) + 
tm_borders() +
   tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
#          legend.position = c("top","right"),
          legend.bg.alpha = 1) +       
   tm_polygons(col = "Isschoolclosed", title="School Status",
               style = "fixed",
              breaks = c(0, 0.9, 2),
              labels = c("Not Closed", "Closed")
               )
```


```{r load-Catholic, include=FALSE}
DAcath <- st_read("./ArcGIS/CATHOLIC", layer = "Join_Cath")
DAcath <- mutate(DAcath, DAUID = as.integer(as.character(DAUID)))
DAcath <- DAcath %>% 
  rename(
    Cath_CLOSED = Max_CLOSED
    )
st_geometry(DAcath) <- NULL
DAcath <- DAcath %>% select(DAUID, Cath_CLOSED)
DAsj2 <- inner_join(DAsj, DAcath)
DAsj2$Isschoolclosed2 <- as.numeric(DAsj2$Cath_CLOSED==1 | DAsj2$Cath_CLOSED==2)
```


```{r print-Cath-map, echo = FALSE, fig.cap="\\label{fig:Cath-map} Map of DAs with Catholic primary school closures"}
#new tmap with bbox
tm_shape(DAsj2, bbox = ham_bb) + 
tm_borders() +
   tm_layout(legend.title.size = 1,
          legend.text.size = 0.6,
#          legend.position = c("top","right"),
          legend.bg.alpha = 1) +       
   tm_polygons(col = "Isschoolclosed2", title="School Status",
               style = "fixed",
              breaks = c(0, 0.9, 2),
              labels = c("Not Closed", "Closed")
               )
```


Exploratory Analysis
====================

```{r}
library(gridExtra)
```

An initial investigation can use density plots to determine whether there is a difference in catchments, between those with a school closure and those without, for various variables in the census data. In Figure \ref{fig:densityplots}, for example, it can be seen that for both the HWDSB and HWCDSB, schools from catchments with a lower average after-tax household income were more likely to be closed; this, however, could certainly be due to the difference in incomes across Hamilton, since areas seeing housing growth (and thus high utilization of schools) are less likely to see school closures, while older areas with no housing growth (and thus possible under-utilization of schools that were built for a larger child population) would be more likely to see schools close. Contrast this with the density plots for DA delta income in Figure \ref{fig:deltaincomeplots}, for example: neighbourhoods showing lower income growth from 2006 to 2016 seem to be slightly _less_ likely to see their school close.


```{r fig-right-left-panel-plot, echo = FALSE, fig.cap="\\label{fig:densityplots} Income characterists of closed and non-closed DAs"}
# Recreate Figure 1
a <- ggplot(DAsj, aes(x = AVGAFTERTAXINCHH2006))
a <- a + geom_density(aes(color = as.factor(Isschoolclosed))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Public schools",x="DA 2006 average income", y = "Density", col="School Closed")
a <- a + theme(legend.position="bottom") 
#
b <- ggplot(DAsj2, aes(x = AVGAFTERTAXINCHH2006))
b <- b + geom_density(aes(color = as.factor(Isschoolclosed2))) +
  geom_vline(aes(xintercept = mean(deltaincome)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Catholic schools",x="DA 2006 average income", y = "Density", col="School Closed")
b <- b + theme(legend.position="bottom")
grid.arrange(a, b, ncol = 2)
```


```{r fig-right-left-panel-plot2, echo = FALSE, fig.cap="\\label{fig:deltaincomeplots} Delta income characterists of closed and non-closed DAs"}
# Recreate Figure 
c <- ggplot(DAsj, aes(x = (deltaincome)))
c <- c + geom_density(aes(color = as.factor(Isschoolclosed))) +  xlim(NA,2.5) +
  geom_vline(aes(xintercept = mean(deltapop0to14)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Public schools",x="DA delta income (%)", y = "Density", col="School closed")
c <- c + theme(legend.position="bottom") 
#
d <- ggplot(DAsj2, aes(x = (deltaincome)))
d <- d + geom_density(aes(color = as.factor(Isschoolclosed2))) + xlim(NA,2.5) +
  geom_vline(aes(xintercept = mean(deltapop0to14)), 
             linetype = "dashed", size = 0.6) +
  labs(title="Catholic schools",x="DA delta income (%)", y = "Density", col="School closed")
d <- d + theme(legend.position="bottom")
grid.arrange(c, d, ncol = 2)
```


Methodology
===========

we will do a bit of exploratory analysis, then a probit 

- do one
- then charts with results

- do another one for Catholic primary schools, chart the results




 

```{r}
myprobit <- glm(Isschoolclosed ~ deltaincome + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj)
summary(myprobit)
```


```{r}
myprobit2 <- glm(Isschoolclosed2 ~ deltaincome + deltapop0to14 + POP0TO142006 + log(AVGAFTERTAXINCHH2006) + PERCLOWINC0TO52006, family = binomial(link = "probit"), data = DAsj2)
summary(myprobit2)
```





Probit
======


Addendum?
=========

Can we also wwork with the data files to do another regression on school age in 2016 versus neighbourhood characteristics? It looks like poor children did get given newer schools.









The Elsevier article class
==========================

#### Installation

If the document class *elsarticle* is not available on your computer,
you can download and install the system package *texlive-publishers*
(Linux) or install the LaTeX package *elsarticle* using the package
manager of your TeX installation, which is typically TeX Live or MikTeX.

#### Usage

Once the package is properly installed, you can use the document class
*elsarticle* to create a manuscript. Please make sure that your
manuscript follows the guidelines in the Guide for Authors of the
relevant journal. It is not necessary to typeset your manuscript in
exactly the same way as an article, unless you are submitting to a
camera-ready copy (CRC) journal.

#### Functionality

The Elsevier article class is based on the standard article class and
supports almost all of the functionality of that class. In addition, it
features commands and options to format the

-   document style

-   baselineskip

-   front matter

-   keywords and MSC codes

-   theorems, definitions and proofs

-   lables of enumerations

-   citation style and labeling.

Front matter
============

The author names and affiliations could be formatted in two ways:

(1) Group the authors per affiliation.

(2) Use footnotes to indicate the affiliations.

See the front matter of this document for examples. You are recommended
to conform your choice to the journal you are submitting to.

Bibliography styles
===================

There are various bibliography styles available. You can select the
style of your choice in the preamble of this document. These styles are
Elsevier styles based on standard styles like Harvard and Vancouver.
Please use BibTeXÂ to generate your bibliography and include DOIs
whenever available.






changing the flag values to suit the rubric in Figure \ref{fig:pubschoolclassrubric}:

```{r table1-create, echo = FALSE}
table1.df <- data.frame(Flag = c("0", "1", "2", "3", "4", "9"),
                        Meaning = c("DA is completely outside closed catchment", 
                                    "DA is completely inside closed catchment", 
                                    "DA is about 70-90% inside closed catchment", 
                                    "DA is about 30-70% inside closed catchment", 
                                    "DA is only 10-30% inside closed catchment", 
                                    "DA is outside closed catchment with coincident edge"))
kable(table1.df) %>% kable_styling(latex_options = c("scale_down"))
```














Here are two sample references: @Feynman1963118 [@Dirac1953888].

References {#references .unnumbered}
==========